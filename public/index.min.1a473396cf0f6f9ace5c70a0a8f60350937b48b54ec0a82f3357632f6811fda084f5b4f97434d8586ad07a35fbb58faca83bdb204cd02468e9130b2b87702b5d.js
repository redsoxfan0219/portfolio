var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description","lead"],index:["title","description","lead"]}});e.add({id:0,href:"/code/datadictionarycreator/",title:"Data Dictionary Creator",description:`My first Python package, adamic, is a simple solution for creating data dictionaries.
Installation # The package is available on PyPi and can be downloaded by running the following from the command line:
pip install adamic Use # After installing the package to your environment, import the package to your script, Jupyter notebook, or directly to the python3 command line.
from adamic import adamic To create your data dictionary, pass a Pandas dataframe to the create_data_dictionary() function:`,content:`My first Python package, adamic, is a simple solution for creating data dictionaries.
Installation # The package is available on PyPi and can be downloaded by running the following from the command line:
pip install adamic Use # After installing the package to your environment, import the package to your script, Jupyter notebook, or directly to the python3 command line.
from adamic import adamic To create your data dictionary, pass a Pandas dataframe to the create_data_dictionary() function:
adamic.create_data_dictionary(sample_df) The package will prompt you to supply definitions for each variable in the dataset. Hit Enter after supplying definition or if you want to define the variable later after the output file has been created.
Finally, you will be prompted to name your preferred file extension. .csv, .json, and .xlsx are the available options.
Source Code # The source code for adamic can be found at this GitHub repository.
`}),e.add({id:1,href:"/docs/api-documentation/",title:"API Documentation",description:"A sample of my API Documentation",content:`Coming soon!
`}),e.add({id:2,href:"/code/exploratorydataanalysis/",title:"Exploratory Data Analysis",description:"Samples of past EDA",content:`Double-click the README.md in the interactive window for more information.
For other examples of my data science projects, check out this GitHub repository.
`}),e.add({id:3,href:"/docs/model-documentation/",title:"Model Documentation",description:"A sample of AI/ML Model Documentation",content:`Below is an example of AI-ML documentation that I\u0026rsquo;ve created in the past. The content of this text is designed meet expectations set in the Federal Reserve\u0026rsquo;s SR 11-7: Guidance on Model Risk Management.
Note: all proprietary details have been removed and the specific model attributes have been genericized.
Model Overview # Model Purpose # The purpose of Super Fantastic Superior Sample Weather Model (herafter \u0026ldquo;Sample Weather\u0026rdquo; or \u0026ldquo;the model\u0026rdquo;) is to predict Fantastic Insurance Co.\u0026rsquo;s claim losses and loss frequencies following a catastrophic (\u0026ldquo;CAT\u0026rdquo;) wind-rain event, such as a hurricane.
Currently, when a severe weather event occurs, Fantastic Insurance actuaries produce loss and frequencies estimates by reviewing past wind-rain events and applying a multiplication factor to the cost and frequencies of the previous event. This approach has proven ineffective at gauging losses and frequencies, especially when the present event differs dramatically in size and location from past wind-rain events.
The goal of the Sample Weather model is to use advancend analytics technicques to a) predict losses and frequencies more accurately; b) produce predictions more quickly than current practice allows; and c) to continue producing predictions for the 30 days following a wind-rain event.
Model Characteristics # Attribute Value Model Name Sample Weather Model Model ID No. 867-5309 Model Owner Tommy Tutone Model Client Jenny Jenny Production Date November 16, 1981 Deployment SageMaker Image ID 325389189899.dkr.ecr.us-east-2.amazonaws.com/sampleenvironment-sampleweathermodel-dev-deploy:latest Repository Details # Production Repository
https://github.com/redsoxfan0219/master/sampleweathermodel
Development Repository
https://github.com/redsoxfan0219/develop/sampleweathermodel
ETL Code
https://github.com/redsoxfan0219/ETL/sampleweathermodel
Final Training Data
s3://sample-environment/sampleweathermodel/eda/train/
Model Outputs # Implementation Details # Production Data # Data Input #1 # Data Input #2 # Data Input #3 # Past Model Objects.
Methodology, Assumptions, and Parameters # Controls # Ongoing Monitoring # Model Development # Training Data # Exploratory Data Analysis # Data Decisions # Methodology Experiments # # `}),e.add({id:4,href:"/code/rentext/",title:"RenText",description:"RenText is my ongoing effort to use Python and advanced analytics to analyze Renaissance English texts. The data used in this project is from the Early English Books Online (EEBO) Text Creation Partnership.",content:`RenText is my ongoing effort to use Python and advanced analytics to analyze Renaissance English texts. The data used in this project is from the Early English Books Online (EEBO) Text Creation Partnership.
`}),e.add({id:5,href:"/docs/package-documentation/",title:"Package Documentation",description:"Coming soon!",content:`Coming soon!
`}),e.add({id:6,href:"/code/",title:"Code",description:"",content:""}),e.add({id:7,href:"/docs/",title:"Docs",description:"",content:""}),e.add({id:8,href:"/graphics/",title:"Graphics",description:"",content:""}),e.add({id:9,href:"/graphics/processflow/",title:"Process Flow",description:"A sample process flow map",content:`Process flow maps are vital to technical documentation. Whether used to describe business processes or data product architecture, they help everyone get on the same page by visualizing the abstract.
There are several software programs out there that can be used to create process flow maps. I\u0026rsquo;m most familiar with Microsoft Visio, a program in which I\u0026rsquo;ve developed custom templates and custom stencils. I am also familiar with Miro and FigJam, for which I\u0026rsquo;ve built basic plugins using TypeScript via the Figma Plugin API.
In my past work, I have used process flow maps primarily to visualize how AI/ML models are structured. With the help of my process flow maps, confused business partners and those outside the dev project team can begin to understand how a data product is functioning.
Below is a generic example of the kind of diagram I complete regularly in Visio. As you can see, this diagram visualizes how data comes into a model, how it is transformed, how it is processed, and what happens to outputs after they are produced.
`}),e.add({id:10,href:"/graphics/linkedinpost/",title:"LinkedIn Post",description:`Occasionally, I\u0026rsquo;ve been asked to produce graphics for social media posts on sites like LinkedIn. My go-to software for such requests is Adobe Illustrator.
One recent request was for a graphic celebrating my department\u0026rsquo;s cohort of incoming interns. I took pains to ensure consistency with enterprise-wide brand standards and recent section-wide guidance on social media engagement. Here\u0026rsquo;s what I came up with:`,content:`Occasionally, I\u0026rsquo;ve been asked to produce graphics for social media posts on sites like LinkedIn. My go-to software for such requests is Adobe Illustrator.
One recent request was for a graphic celebrating my department\u0026rsquo;s cohort of incoming interns. I took pains to ensure consistency with enterprise-wide brand standards and recent section-wide guidance on social media engagement. Here\u0026rsquo;s what I came up with:
`}),e.add({id:11,href:"/personal/",title:"Personal",description:"Before I started working in technical writing, I was an academic specializing in Renaissance English literature. I got my PhD at Ohio State. If you\u0026rsquo;re having trouble sleeping, you can read my dissertation. As you might expect from someone who studied literature, I like to read a lot. I still read Renaissance literature occasionally — Edmund Spenser and John Milton are still among my favorites. I\u0026rsquo;ve also come to really enjoy the work of Marcel Proust.",content:`Before I started working in technical writing, I was an academic specializing in Renaissance English literature. I got my PhD at Ohio State. If you\u0026rsquo;re having trouble sleeping, you can read my dissertation. As you might expect from someone who studied literature, I like to read a lot. I still read Renaissance literature occasionally — Edmund Spenser and John Milton are still among my favorites. I\u0026rsquo;ve also come to really enjoy the work of Marcel Proust. Beyond \u0026ldquo;highbrow literature\u0026rdquo;, I read widely in sociology, politics, natural history, music, and popular science. This, this, and this are a few books I read recently and enjoyed. During the pandemic, a friend introduced me to fly fishing, which has become a big part of my life. I try to spend at least a couple days a month on a river — even in the winter. Here\u0026rsquo;s a photo of me on the Au Sable River in Michigan in December. It was a very brisk 29°F with a wind chill of 6°! And, alas, no fish that day to offset the bitter cold.
I also like spending time with my family. My wife Nadia and I have been married for about five years. We recently got kayaks that we\u0026rsquo;ve been enjoying taking them out on the local waterways.
We also have a pug named Maple, who likes to think of herself as a guard dog. In truth, she\u0026rsquo;s better at sleeping than she is at scaring away the mailman and local joggers. Occasionally, she\u0026rsquo;ll take a break from her busy life to pose for a photo.
`}),e.add({id:12,href:"/",title:"Hi, I'm Ben Moran.",description:"Technical Writing, Documentation, Information Architecture",content:""}),e.add({id:13,href:"/resume/",title:"Resume",description:"The formal record of my past work and education",content:`Experience # Senior Documentation Engineer
Nationwide Mutual Insurance Company, Enterprise Analytics Office
2019—Present
Provide end-to-end documentation services for a variety of technical audiences, including data scientists, executives, internal auditors, and state regulators Lead change management and training efforts on topics such as CI/CD and MLOps Read and write sample code (Python, R, and SQL) for documentation purposes Collaborate with software engineers, data scientists, data engineers, and other subject matter experts within Agile framework Supervise the work of three junior documentation engineers Develop and curate technical content—e.g., sample code, training videos, instructional manuals— for enterprise data scientists on topics such as Docker, Kubernetes, Kubeflow, and AWS products (S3, SageMaker, CloudWatch) Edit whitepapers on technical subjects such as natural language processing, gradient boosting machines, exploratory data analysis best practices, etc. Use scripting languages (Python, R, PowerShell) to develop tools to automate tasks such as environment configuration and documentation processes Analyst Intern
US Government Accountability Office, Contracting and National Security Acquisitions
2018—2019
Audited US Department of Defense major defense acquisition programs Wrote and edited technical reports on military spending and acquisition practices Graduate Teaching Associate
The Ohio State University, Department of English
2016—2018
Taught college writing and literature classes to more than 300 students Facilitated content in-person and online Education # PhD, English — The Ohio State University (2020)
MA, English — The University of Alabama (2015)
BA, English — Western Michigan University (2013)
Skills \u0026amp; Technology # Technical Writing Developer Documentation Model Documentation API Documentation Package Documentation (Python, R) Docs as Code Editing Copyediting Proofreading Qualitative Research Model Risk Management Project Management Corporate Training Developing content for technical audiences Learning Development Instructional Design Model Development Lifecycle Python R SQL SharePoint Git/GitHub MS Office HTML/CSS Terminal/PowerShell `}),e.add({id:14,href:"/contributors/",title:"Contributors",description:"",content:""}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()